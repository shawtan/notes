<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="shawnotes.css" type="text/css" />
</head>
<body>
<h1 id="cs-350-notes">CS 350 Notes</h1>
<p>Written by Shaw Tan</p>
<hr />
<h1 id="threads-and-concurrency">Threads and Concurrency</h1>
<h2 id="thread">Thread</h2>
<ul>
<li>Way to express concurrency in a program</li>
<li>A normal <em>sequential program</em> consists of a single thread of execution</li>
<li><em>Threaded concurrent programs</em> have multiple threads of execution occuring at the same time</li>
</ul>
<h3 id="os161">OS/161</h3>
<ul>
<li>A thread creates new threads using <code>thread_fork</code></li>
<li>Each thread's function activations are <em>private</em></li>
<li><code>thread_yield</code> gives up control of the current thread (voluntary)</li>
<li><code>thread_exit</code> ends the current thread</li>
</ul>
<h3 id="gdb-commands">GDB Commands</h3>
<pre><code>c              Continue
l              Lines
b [func name]  Create a break point
bt             Backtrace</code></pre>
<h3 id="implementation">Implementation</h3>
<p>Multiple processors, multiple cores, hardware multithreading per core</p>
<ul>
<li>Threads can execute simultaneously</li>
<li>Problem: Upper bound on number of threads</li>
<li>Problem: Still consuming resources while a thread is waiting (waste of a core)</li>
</ul>
<p>Time sharing</p>
<ul>
<li>Multiple threads share the same hardware thread</li>
<li>Quick switches between threads so it feels like every thread is running at the same time</li>
</ul>
<h3 id="context-switch">Context Switch</h3>
<ul>
<li>The switch from one thread to another is called a <em>context switch</em>
<ol style="list-style-type: decimal">
<li>Decide which thread will run next (scheduling)</li>
<li>Save register contents of current thread</li>
<li>Load register contents of next thread</li>
</ol></li>
<li>This must be done very carefully</li>
<li>Caused by
<ul>
<li><code>thread_yield</code></li>
<li><code>thread_exit</code></li>
<li><code>wchan_sleep</code> Wait channel sleep (Blocked)</li>
<li>Thread is <em>preempted</em> (Thread involuntarilty stopped)</li>
</ul></li>
</ul>
<h3 id="thead-states">Thead states</h3>
<ul>
<li><strong>Running</strong>: currently executing</li>
<li><strong>Ready</strong>: ready to execute</li>
<li><strong>Blocked</strong>: waiting for something, not ready</li>
</ul>
<h3 id="preemption">Preemption</h3>
<ul>
<li><em>Preemption</em> forces a running thread to stop running</li>
<li>To implement this, there needs to be a means of 'getting control' of a thread</li>
<li>Done using <em>interrupts</em></li>
</ul>
<h3 id="interrupts">Interrupts</h3>
<ul>
<li>Part of hardware devices (e.g Timer)</li>
<li>Causes hardware to automatically transfer control to a fixed location in memory</li>
<li>Place an <em>interrupt handler</em> in that memory location</li>
<li>The <em>interrupt handler</em>
<ol style="list-style-type: decimal">
<li>Creates a <em>trap frame</em> to record thread context (saves ALL registers)</li>
<li>Determines which device caused the interrupt and performs device-specific processing</li>
<li>Restores the saved thread context from trap frame and resumes execution</li>
</ol></li>
</ul>
<h3 id="preemptive-scheduling">Preemptive Scheduling</h3>
<ul>
<li>A preemptive scheduler limits how long a thread can run before being preempted</li>
<li>Set a threshold of how often a thread can be intrrupted before being preempted</li>
</ul>
<h1 id="synchronization">Synchronization</h1>
<h2 id="thread-synchronization">Thread Synchronization</h2>
<ul>
<li>When threads need to talk to each other, synchronization problems can occur</li>
<li>Threads have shared access to global variables</li>
<li>What happens when two threads try to modify the same variable at the same time? UNDEFINED behaviour</li>
</ul>
<h2 id="mutual-exclusion">Mutual Exclusion</h2>
<ul>
<li>A <strong>critical section</strong> is a section accessing a shared object</li>
<li>Only one thread can be running a <em>critical section</em> of code at one time</li>
<li>Do this with locks
<ul>
<li><code>Acquire</code> / <code>Release</code> locks</li>
</ul></li>
</ul>
<h3 id="hardware-specific-implementation">Hardware-specific implementation</h3>
<ul>
<li>Use an <em>atomic</em> instruction that is indivisible</li>
<li>x86 <code>xchg</code> instruction:
<ul>
<li><code>xchg src,addr</code>
<ul>
<li><code>src</code> is a register</li>
<li><code>addr</code> is a memory address</li>
<li>Exchanges values in <code>src</code> and <code>addr</code></li>
</ul></li>
</ul></li>
<li>MIPS
<ul>
<li>load-linked <code>ll</code>
<ul>
<li>Places a watch on a variable</li>
</ul></li>
<li>store-conditional <code>sc</code>
<ul>
<li>Fails if the watched variable has been modified</li>
</ul></li>
</ul></li>
</ul>
<h2 id="spinlocks">Spinlocks</h2>
<ul>
<li><code>spinlock_init</code></li>
<li><code>spinlock_acquire</code></li>
<li><code>spinlock_release</code></li>
<li><em>Problem:</em> Wasted cycles just 'spinning' waiting for the lock to release</li>
</ul>
<h2 id="locks">Locks</h2>
<ul>
<li>Notify the thread when lock is available</li>
<li><code>lock_acquire</code> thread blocks after calling this</li>
<li><code>lock_release</code>
<ul>
<li>Have a thread id attached, so only the acquiring thread can release the lock</li>
<li>Kernel panic if the ids don't match!</li>
</ul></li>
</ul>
<h3 id="blocking-in-os161">Blocking in OS/161</h3>
<ul>
<li><code>wchan_sleep(wchan)</code> blocks thread and adds it to wchan queue
<ul>
<li>Call <code>wchan_lock</code> before this</li>
</ul></li>
<li><code>wchan_wakeall(wchan)</code> wakes up all threads on <code>wchan</code> queue</li>
<li><code>wchan_wakeone(wchan)</code> wakes the oldest thread on wchan</li>
<li><code>wchan_lock(wchan)</code> prevents operations on wchan
<ul>
<li>So only 1 thread can be added to the queue at once</li>
</ul></li>
<li>wchan uses a spinlock</li>
<li>Hoping that wchan critical channel is smaller than code critical section</li>
</ul>
<h2 id="semaphore">Semaphore</h2>
<ul>
<li>Synchronization primitive used to enforce mutual exclusion</li>
<li>Two atomic operations:
<ul>
<li><code>P</code>: If value greater than 0, decrement value. Otherwise block until value is greater than 0 and then decrement</li>
<li><code>V</code>: Increment value of the semaphore</li>
</ul></li>
<li>No restriction that only same thread can call <code>P</code> and <code>V</code></li>
<li>e.g Mutual exclusion</li>
</ul>
<pre><code>    Thread 1:
        P(sem);
          total++;
        V(sem);

    Thread 2:
        P(sem);
          total--;
        V(sem);</code></pre>
<ul>
<li>e.g Producer/Consumer synchronization</li>
</ul>
<pre><code>    Producer’s Pseudo-code:
      P(Spaces);
      add item to the buffer
      V(Items);

    Consumer’s Pseudo-code:
      P(Items);
      remove item from the buffer
      V(Spaces);</code></pre>
<h2 id="condition-variables">Condition Variables</h2>
<ul>
<li>Synchronization primative</li>
<li>3 operations
<ul>
<li><code>wait</code> causes the current thread to block</li>
<li><code>signal</code> unblocks one thread on the signalled condition variable</li>
<li><code>broadcast</code> wakes all threads waiting on the condition</li>
</ul></li>
<li>e.g Producer / Consumer variable
<ul>
<li>Two condition variables:
<ul>
<li><code>notempty</code> (count &gt; 0)</li>
<li><code>notfull</code> (count &lt; N)</li>
</ul></li>
</ul></li>
</ul>
<h2 id="deadlocks">Deadlocks</h2>
<ul>
<li>e.g 2 threads T1, T2</li>
</ul>
<pre><code>    T1:
        lock_acquire(lockA)
        lock_acquire(lockB)
    T2:
        lock_acquire(lockB)
        lock_acquire(lockA)</code></pre>
<ul>
<li>The threads are permanently stuck</li>
</ul>
<h3 id="deadlock-recovery">Deadlock Recovery</h3>
<ul>
<li>Release all locks and try again</li>
<li>Restart the offending device (kill the threads)</li>
<li>Problem: Deadlock recovery tends to break the program</li>
</ul>
<h3 id="deadlock-avoidance">Deadlock Avoidance</h3>
<ul>
<li>Tell OS all resources the thread needs, only run when they're available</li>
<li><em>Problem:</em> A thread may not know all resources it needs so it requests all of them</li>
<li>All threads do this, resulting in only one thread runnning</li>
</ul>
<h3 id="deadlock-prevention">Deadlock Prevention</h3>
<ul>
<li>Remove a requirement of deadlocks:
<ul>
<li>Has locks (mutual exclusion)</li>
<li>No resource preemption (threads with different priorities)</li>
</ul></li>
<li>No Hold and Wait
<ul>
<li>Prevent a thread from requesting resources if it has resources allocated</li>
<li>Must acquire all resources at once</li>
<li><em>Problem:</em> Creates livelocks where each resource is trying to re-acquire resources
<ul>
<li>e.g Four cars arrive at a stop sign at the same time</li>
<li>Livelock breaks when one thread just GOES</li>
</ul></li>
</ul></li>
<li>Resource Ordering (use this)
<ul>
<li>Requre each thread acquire resources in increasing resource type order</li>
</ul></li>
</ul>
<h2 id="example-problem">Example Problem</h2>
<ul>
<li>Threaded programs with <code>N</code> queues.</li>
<li>Implement <code>Transfer(i,j)</code> that takes something from queue <code>i</code> and puts it in queue <code>j</code></li>
</ul>
<pre><code>    Transfer(i,j) {

        // Acquire locks in increasing order
        if (i &lt; j) {
          lock_acquire(lock[i]);
          lock_acquire(lock[j]);
        } else {
          lock_acquire(lock[j]);
          lock_acquire(lock[i]);
        }

        // Transfer the item
        list_remove(l[i]);
        list_remove(l[j]);

        // Release locks
        lock_release(lock[i]);
        lock_release(lock[j]);
    }</code></pre>
<h2 id="example-problem-1">Example Problem</h2>
<ul>
<li>Traffic intersection</li>
<li>Allowed:
<ol style="list-style-type: decimal">
<li>Same origin</li>
<li>Opposing direction</li>
<li>A Right turn + Different destination</li>
</ol></li>
<li><code>intersection_before_entry</code>
<ol style="list-style-type: decimal">
<li>Acquire lock</li>
<li>Look at cars in intersection</li>
<li>Block on condition variable until it can go</li>
<li>Get woken up and check until it can go (maybe have a queue)</li>
<li>Go</li>
</ol></li>
<li><code>intersection_after_exit</code>
<ol start="6" style="list-style-type: decimal">
<li>Exit and Brodcast cv</li>
</ol></li>
</ul>
<h1 id="processes-and-system-calls">Processes and System Calls</h1>
<h2 id="process">Process</h2>
<ul>
<li>Environment in which an application program runs</li>
<li>Container for resources required to run an application</li>
<li>Has virtual memory</li>
<li>Isolates program from other programs in other processes</li>
</ul>
<h2 id="system-calls">System Calls</h2>
<ul>
<li>Interface between processes and kernel</li>
<li>A process uses system calls to request OS services</li>
<li>Protects kernel from programs</li>
<li>e.g Create, destroy, manage processes, create, destroy, read, write files</li>
<li><code>syscall library</code> grants privileges to the application</li>
</ul>
<h2 id="kernel-privilege">Kernel Privilege</h2>
<ul>
<li>Requires Hardware support</li>
<li>You can only read and write kernel data when you have the privileges</li>
<li>Prevents programs from messing with the kernel
<ul>
<li>e.g Halting the CPU</li>
</ul></li>
</ul>
<h2 id="how-system-calls-work">How System Calls Work</h2>
<p>Two things can make kernel code run:</p>
<ul>
<li>Interrupts
<ul>
<li>Jump to interrupt handler in the kernel</li>
</ul></li>
<li>Exceptions
<ul>
<li>Exceptions cause a jump to exception handler in kernel</li>
</ul></li>
</ul>
<h3 id="system-call-timeline">System call Timeline</h3>
<ol start="0" style="list-style-type: decimal">
<li>Arranges registers for call</li>
<li>Application calls library wrapper</li>
<li>Library preforms <code>syscall</code></li>
<li>Kernel exception handler runs
<ul>
<li>Create trap frame</li>
<li>Determine exception type</li>
<li>Determine system call being requested</li>
<li>Does the work for system call</li>
<li>Restores application state</li>
<li>Returns</li>
</ul></li>
<li>Library wrapper finishes and returns</li>
<li>Application continues execution</li>
</ol>
<h3 id="exception-types">Exception Types</h3>
<pre><code>EX_IRQ    0    Interrupt   (Interrupt is a type of exception)
EX_SYS    8    Syscall</code></pre>
<h3 id="how-to-tell-type-of-system-call">How to tell type of system call</h3>
<ul>
<li>Kernel defines a code for each system call it understands</li>
<li>Application places a code in a specified location</li>
<li>See <code>syscall.h</code></li>
</ul>
<h2 id="user-and-kernel-stacks">User and Kernel Stacks</h2>
<p>User (Application) Stack</p>
<ul>
<li>Used while code is executing</li>
<li>Located in application's virtual memory</li>
</ul>
<p>Kernel Stack</p>
<ul>
<li>Used while thread is executing kernel code (after exception or interrupt)</li>
<li>Stack also holds trap frames and switch frames</li>
</ul>
<h2 id="exception-handling-in-os161">Exception Handling in OS/161</h2>
<ol style="list-style-type: decimal">
<li>Save application stack pointer</li>
<li>Switch stacks to kernel stack</li>
<li>Saves state in a trap frame</li>
<li>Calls <code>mips_trap</code> which determines the type of exception and handles it (<code>trap.c</code>)</li>
<li>Restore application state</li>
<li>Jump back to application and switch back to unprivileged execution mode</li>
</ol>
<p><code>exception-mips1.S</code></p>
<h2 id="specific-system-calls">Specific System Calls</h2>
<h4 id="fork"><code>fork</code></h4>
<ul>
<li>Creates a (child) process that is identical to the original (parent) process</li>
<li>Returns twice (once to parent, once to child)
<ul>
<li>Return value of parent is pid of child</li>
<li>Return value of child is 0</li>
</ul></li>
<li>Steps
<ol style="list-style-type: decimal">
<li>Create process structure for child process</li>
<li>Create and copy address space from parent to child</li>
<li>Attach address space to child</li>
<li>Assign a PID to the child</li>
<li>Create a thread for the child</li>
<li>Child puts modified trapframe on stack</li>
<li>Go back to userspace</li>
</ol></li>
</ul>
<h4 id="exit"><code>_exit</code></h4>
<ul>
<li>Terminates the calling process</li>
<li>Can pass an exit code which is passed to any other process asking for it</li>
</ul>
<h4 id="waitpid"><code>waitpid</code></h4>
<ul>
<li>Blocks until child terminates</li>
<li>Retrieves exit code of child</li>
</ul>
<h4 id="execv"><code>execv</code></h4>
<ul>
<li>Replaces the program that a process is running</li>
<li>Resets virtual memory and code to that of the new program</li>
<li><code>execv(path, args)</code></li>
<li>Often call <code>fork</code> and <code>execv</code> together</li>
</ul>
<h3 id="terminology">Terminology</h3>
<ul>
<li><strong>Orphan</strong>: When a child is still running when its parent dies</li>
<li><strong>Zombie</strong>: When a child dies before the parent</li>
</ul>
<h1 id="virtual-memory">Virtual Memory</h1>
<h2 id="virtual-memory-1">Virtual Memory</h2>
<ul>
<li>Isolates programs to prevent them from accessing other programs</li>
<li>Each virtual memory is mapped to a different part of physical memory</li>
<li>Address translation is performed in hardware</li>
</ul>
<h3 id="dynamic-relocation">Dynamic Relocation</h3>
<ul>
<li>Track virtual memory <em>offset</em> and <em>limit</em> of each process</li>
<li>Memory Management Unit (MMU) has a <em>relocation register</em> and a <em>limit register</em>
<ul>
<li>Translates virtual address to a virtual address</li>
<li>Kernel maintains R and L for each process and changes the values during context switches</li>
</ul></li>
</ul>
<pre><code>    if v &gt;= L then 
        generate exception
    else 
        p = v + R
</code></pre>
<ul>
<li>Each virtual address space corresponds to a contiguous range of physical addresses</li>
<li>Problem: Physical memory must be contiguous
<ul>
<li>OS must track free and used physical memory</li>
<li>Potential for <em>fragmentation</em> of physical memory</li>
<li>Results in lots of small holes that are unusable by any program</li>
</ul></li>
<li>Problem: Requires hardware support (the MMU)</li>
</ul>
<h3 id="paging">Paging</h3>
<ul>
<li>Physical memory is divided into fixed-sized chunks called <em>frames</em></li>
<li>Virtual memories are divided into fixed-size chunks called <em>pages</em></li>
<li>Page size = Frame size</li>
<li>Each page maps to a different frame</li>
<li>Does this require hardware support? Yes
<ul>
<li>Possibly a relocation register for every page</li>
<li>Actually use a Page Table</li>
</ul></li>
<li>Does this solve fragmentation problem?
<ul>
<li>Not completely; there is internal fragmentation.</li>
<li>Smallest unit of memory is 1 page (4kb), a program may not need that much</li>
</ul></li>
</ul>
<h4 id="page-table">Page Table</h4>
<ul>
<li>Has entry for every page-frame mapping in virtual address space</li>
<li>Has a <em>valid</em> bit indicating if the mapping is in use (has physical address)</li>
<li>Cannot have two page table entries pointing to the same frame (then two programs will share memory)</li>
<li>Need 12 bits (4kb) to determine offset, the rest is location</li>
<li>Don't put page number in page table! Use indexes instead</li>
<li>Can also have other information (set by MMU)
<ul>
<li>Write Protection bit: makes a page read only
<ul>
<li>Use for code segment</li>
</ul></li>
<li>Reference bit: When page is being read / written to
<ul>
<li>Can swap out unused pages to free up memory</li>
</ul></li>
<li>Dirty bit: When page contents change
<ul>
<li>Need to write to disk</li>
<li>Cheaper swap operation for non-dirty pages</li>
</ul></li>
</ul></li>
<li>Page Table Size = number of pages * size of page table entry</li>
<li>Number of pages = virtual memory size / page size</li>
<li>Located inside the kernel</li>
<li>Problem: need to do a page lookup every time (expensive)</li>
<li>Problem: Page table can be really big</li>
</ul>
<h3 id="hardware">Hardware</h3>
<h4 id="kernel">Kernel</h4>
<ul>
<li>Manage MMU registers on address space switches (context switches)</li>
<li>Creates and managers page tables</li>
<li>Allocates and deallocates physical memory</li>
<li>Handles MMU exceptions</li>
</ul>
<h4 id="mmu-memory-management-unit">MMU (Memory Management Unit)</h4>
<ul>
<li>Translates virtual addresses to physical addresses</li>
<li>Check for and raise exceptions when necessary</li>
<li>Steps
<ol style="list-style-type: decimal">
<li>Check for entry <code>(p, f)</code> in TLB. If it's there, return <code>f</code></li>
<li>Find <code>p</code>'s frame number <code>f</code> in page table</li>
<li>Add <code>(p, f)</code> to TLB (kick out old entry if full)</li>
<li>Return <code>f</code></li>
</ol></li>
<li>Needs to be able to distinguish different address spaces</li>
</ul>
<h4 id="tlb-translation-lookaside-buffer">TLB (Translation Lookaside Buffer)</h4>
<ul>
<li>Reduces memory lookup cost (page table, translation, actually getting memory)</li>
<li>Caches page translations</li>
<li>Small, limited amount of entries</li>
<li>Kernel clears or invalidates TLB on context switches</li>
</ul>
<h4 id="hardware-vs-software-managed-tlb">Hardware vs Software Managed TLB</h4>
<ul>
<li>Hardware-managed TLBs are not very flexible
<ul>
<li>MMU must handle page misses and entry replacement</li>
</ul></li>
<li>Software-managed TLBs throw an exception if an entry does not exist</li>
</ul>
<h3 id="solving-page-table-memory-problem">Solving Page Table Memory Problem</h3>
<ul>
<li>A page table needs to be really big to store all page-frame translations, even when a program only uses a few pages</li>
<li>Solution: Have a <strong>limit register</strong> of the farthest place memory is used
<ul>
<li>Doesn't actually work, memory is not laid out nicely</li>
<li>Stack is placed farther out and grows inwards</li>
</ul></li>
<li>Solution: <strong>Segmentation</strong>
<ul>
<li>Offset register + Limit register per segment</li>
<li>Program has a couple of segments</li>
<li>Segment is decided by segment ID in first few bits</li>
<li><em>Problem</em>: External fragmentation</li>
</ul></li>
<li>Solution: <strong>Two-Level Paging</strong>
<ul>
<li>Split page table into multiple smaller page tables</li>
<li>Only split a smaller table if entires in it are valid</li>
<li>Save memory by not creating page tables for unused addresses</li>
<li><em>Problem</em>: Needs large page table directory for large address spaces</li>
</ul></li>
<li>Solution: <strong>Multi-Level Paging</strong>
<ul>
<li>Multiple levels of directory</li>
<li>Can accommodate large and small programs without taking a lot of space</li>
<li><em>Problem</em>: TLB misses are more expensive because you need to look up multiple page tables</li>
</ul></li>
</ul>
<h4 id="translating-segment-addresses">Translating Segment Addresses</h4>
<ul>
<li>First k bits: which segment it belongs to</li>
<li>Remaining bits: Check with that segment's limit register for validity</li>
<li>Use relocation offset of that segment to get physical address</li>
</ul>
<h4 id="translating-two-level-paging-addresses">Translating Two-Level Paging Addresses</h4>
<ul>
<li>Each virtual address has three parts:
<ul>
<li><code>p1</code>: Lookup in <code>base register</code></li>
<li><code>p2</code>: Lookup in 2nd level page table</li>
<li><code>o</code>: offset</li>
</ul></li>
</ul>
<h2 id="os161-virtual-memory">OS/161 Virtual Memory</h2>
<ul>
<li><code>dumbvm</code></li>
<li>32-bit paged virtual and physical addresses</li>
<li>Software-managed TLB
<ul>
<li>Exception is raised on every TLB miss</li>
</ul></li>
<li><code>vm_fault</code> handles TLB exceptions
<ul>
<li>Uses information from <code>addrspace</code> structure to determine page-frame mappings to load into TLB</li>
<li>Separate <code>addrspace</code> for each process</li>
<li>Stack size not specified because it is hardcoded
<ul>
<li>12 pages</li>
<li>Page size 0x1000</li>
<li>Starts at end of virtual memory
<ul>
<li>e.g 0x8000 0000 space -&gt; 0x7FFF 4000</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h3 id="initializing-an-address-space">Initializing an Address Space</h3>
<ul>
<li>A kernel must create an address space for each process it creates</li>
<li>Program's code and data is described in an executable file created when program is compiled and linked
<ul>
<li>ELF (Executable and Linking Format)</li>
</ul></li>
<li><code>execv</code> system call creates address space and loads process</li>
<li><em>Pre-loading</em>: read entire executable and load all of it (OS/161 does this)
<ul>
<li>Simpler to implement</li>
<li>Don't need to wait to load functions</li>
</ul></li>
<li><em>Loading on demand</em>: Normally OS's will only load parts of program when it is used
<ul>
<li>Saves memory</li>
</ul></li>
</ul>
<h4 id="elf-files">ELF files</h4>
<ul>
<li>Contain address space segment descriptions
<ul>
<li>Header describing segments and segment images
<ul>
<li>Virtual address of start of each segment</li>
<li>Length of segment</li>
<li>Location of start of segment image in ELF file</li>
<li>Length of segment image in ELF file</li>
</ul></li>
<li>Image is an exact copy of the binary data that should be loaded into the specified portion
<ul>
<li>Extra space should be 0-filled</li>
</ul></li>
</ul></li>
<li>Identifies the virtual address of the program's first instruction</li>
<li>Contains information for compilers, linkers, debuggers, loaders, etc.</li>
<li><strong>OS/161</strong> has 2 segments in ELF files (text segment (code) and data segment (global data))</li>
</ul>
<h3 id="virtual-memory-for-kernel">Virtual Memory for Kernel</h3>
<ul>
<li>Ideally, kernel is in virtual memory</li>
<li>Easier to prevent other programs from accessing kernel memory</li>
<li>Problems:
<ul>
<li>Bootstrapping: the kernel implements virtual memory, so how does it run in virtual memory when it's starting</li>
<li>Sharing: data may need to be copied between kernel and applications but they are in separate virtual address spaces
<ul>
<li>Slower and more TLB flushing</li>
<li>Solution: Put kernel in application address space</li>
</ul></li>
</ul></li>
<li><code>kuseg</code>
<ul>
<li>TLB mapped</li>
<li>Contains user segments</li>
</ul></li>
<li><code>kseg0</code>
<ul>
<li>Kernel segment</li>
<li>Unmapped, cached</li>
<li>Mapped to first 512 mb of physical memory</li>
</ul></li>
<li><code>kseg1</code>
<ul>
<li>Unmapped, uncached</li>
<li>Mapped to first 512 mb of physical memory (same as kseg0)</li>
<li>Used to talk to hardware devices</li>
</ul></li>
</ul>
<h2 id="secondary-storage">Secondary Storage</h2>
<ul>
<li>e.g Opening many tabs in a browser. Tabs will be stored to hard drive instead of being kept in RAM</li>
</ul>
<h3 id="resident-set">Resident Set</h3>
<ul>
<li>Set of virtual pages present in physical memory
<ul>
<li>Changes over time as pages are swapped in and out</li>
<li>Also depends on memory pressure</li>
</ul></li>
<li>Tracked with the <em>present</em> bit in the page table
<ul>
<li>1 = Page in memory, 0 = page not in memory</li>
</ul></li>
</ul>
<h3 id="page-faults">Page Faults</h3>
<ul>
<li>Hardware-managed TLB:
<ul>
<li>MMU encounters 0 present bit in PTE</li>
<li>Generate exception</li>
</ul></li>
<li>Software-managed TLB
<ul>
<li>Non present pages should never be in TLB</li>
<li>Only load entires with a 1 present bit</li>
</ul></li>
<li>^ This causes the page fault</li>
<li>Likely no memory available during page fault as memory pressure caused swapped memory</li>
<li>Kernel will
<ol style="list-style-type: decimal">
<li>Swap memory in (likely evicting another page to do so)</li>
<li>Update PTE (present bit, frame address)</li>
<li>Set new page-frame mapping</li>
<li>Return from exception</li>
</ol></li>
</ul>
<h3 id="performance">Performance</h3>
<ul>
<li>Secondary storage is slow
<ul>
<li>Milliseconds for hard drive, microseconds for SSD, nanoseconds for RAM</li>
</ul></li>
<li>Page faults will significantly increase average memory access times</li>
<li>Ways to decrease page faults:
<ul>
<li>Limit number of processes
<ul>
<li><strong>Working set</strong>: number of pages a program actively uses (within period of time)</li>
<li>As long as working set is all resident, page faults are minimal</li>
</ul></li>
<li>Be smart about which pages are kept</li>
<li>Hide latencies (prefetch pages before it's needed)
<ul>
<li>Fetch data from storage in batches is often faster</li>
</ul></li>
</ul></li>
</ul>
<h3 id="program-properties">Program Properties</h3>
<h4 id="locality">Locality</h4>
<ul>
<li>Temporal Locality: Programs are likely to access pages they have accessed recently</li>
<li>Spatial location: Programs are likely to access close together parts of memory</li>
</ul>
<h3 id="page-replacement-policies">Page Replacement Policies</h3>
<h4 id="fifo-first-in-first-out">FIFO (First in First Out)</h4>
<ul>
<li>Replace page that has been in memory the longest</li>
<li>Very simple, but not very good</li>
</ul>
<h4 id="optimal-min">Optimal (MIN)</h4>
<ul>
<li>Replace page that will not be referenced for the longest time</li>
<li>Optimal policy for demand paging</li>
<li>Problem: Requires knowledge of the future</li>
</ul>
<h4 id="lru-least-recently-used">LRU (Least Recently Used)</h4>
<ul>
<li>Replace the least recently used page</li>
<li>Works very well</li>
<li>Problem: very expensive (need to update memory structure every time)</li>
<li>Problem: kernel does not know which pages a program is using unless there's an exception</li>
</ul>
<h4 id="clock-algorithm-second-chance">Clock Algorithm (Second chance)</h4>
<ul>
<li>MMU sets a <em>reference</em> (<em>use</em>) bit when page is used</li>
<li>Scan for entry with 0 reference bit
<ul>
<li>Zero out reference bits as you go</li>
</ul></li>
</ul>
<pre><code>    while use bit of victim is set
       clear use bit of victim
       victim = (victim + 1) % num_frames
    choose victim for replacement
    victim = (victim + 1) % num_frames</code></pre>
<h1 id="cpu-scheduling">CPU Scheduling</h1>
<h2 id="simple-scheduling-model">Simple Scheduling Model</h2>
<ul>
<li>A job has:
<ul>
<li><code>a_i</code> Arrival time</li>
<li><code>r_i</code> Run time</li>
<li><code>f_i</code> Finish time</li>
<li>Response time: arrival to run time</li>
<li>Turnaround time: arrival to finish time</li>
</ul></li>
</ul>
<h3 id="basic-non-preemptive-schedulers">Basic Non-Preemptive Schedulers</h3>
<h4 id="fcfs-first-come-first-serve">FCFS (First come first serve)</h4>
<ul>
<li>Runs jobs in arrival time order</li>
<li>Simple and avoids starvation</li>
<li>Pre-emptive version = round-robin</li>
</ul>
<h4 id="sjf-shortest-job-first">SJF (Shortest job first)</h4>
<ul>
<li>Minimizes average turnaround time</li>
<li>Long jobs may starve</li>
<li>Pre-emptive variant: SRTF (shortest remaining time first)</li>
</ul>
<h2 id="cpu-scheduling-1">CPU Scheduling</h2>
<ul>
<li>'jobs' = threads</li>
<li>Need to achieve balance between <em>responsiveness, fairness</em> and <em>efficiency</em></li>
</ul>
<h4 id="differences-from-simple-scheduling">Differences from Simple Scheduling</h4>
<ul>
<li>Run times are not known</li>
<li>Threads are sometimes blocked</li>
<li>Threads have different priorities</li>
</ul>
<h3 id="multi-level-feedback-queues">Multi-level Feedback Queues</h3>
<ul>
<li>Goal: Good responsiveness for interactive threads and let non-interactive threads make as much progress as possible</li>
<li>Give high priority to interactive threads</li>
<li>Problem: How to determine which threads are interactive</li>
<li>Algorithm:
<ol style="list-style-type: decimal">
<li>Scheduler maintains <code>n</code> round-robin ready queues</li>
<li>Scheduler always chooses a thread from highest non-empty queue</li>
<li>Threads in <code>Q_i</code> use quantum <code>q_i</code> (lower priority threads have larger quanta)</li>
<li>If a running thread is preempted, demote it to a lower queue</li>
<li>If a thread blocks, put it in the highest queue</li>
<li>Periodically move all threads to <code>Q_n</code> to prevent starvation</li>
</ol></li>
</ul>
<h3 id="linux-completely-fair-scheduler-cfs">Linux Completely Fair Scheduler (CFS)</h3>
<ul>
<li>Goal: Ensure each thread gets processor time in proportion to its weight</li>
<li>Each thread is assigned a weight</li>
<li>Algorithm:
<ul>
<li>Track the 'virtual' runtime of each runnable thread</li>
<li>Always run the thread with the lowest virtual runtime</li>
</ul></li>
<li>Virtual runtime = actual runtime adjusted by thread weights
<ul>
<li>Virtual runtime advances slower for higher weight threads</li>
</ul></li>
</ul>
<h3 id="multi-core-scheduling">Multi-core Scheduling</h3>
<ul>
<li>Queue per core vs with a single ready queue</li>
<li>Concerns
<ul>
<li>Contention and Scalability
<ul>
<li>Scaling effects are not as large for queue per core</li>
</ul></li>
<li>Cache Affinity: Cached information on new core may not be as relevant</li>
<li>Load imbalance</li>
</ul></li>
</ul>
<h1 id="devices-and-io">Devices and I/O</h1>
<h3 id="sys161-devices">Sys/161 Devices</h3>
<ul>
<li>Timer/clock</li>
<li>Disk drive</li>
<li>Seral console</li>
<li>Text screen</li>
<li>Network interface</li>
</ul>
<h2 id="device-register">Device Register</h2>
<ul>
<li>You interact with devices through a device register</li>
<li>Different offsets contain different statues and commands</li>
</ul>
<h2 id="device-driver">Device Driver</h2>
<ul>
<li>Part of kernel that interacts with a device
<ol style="list-style-type: decimal">
<li>Write to the device register</li>
<li>Repeatedly <em>poll</em> until status is <code>complete</code></li>
<li>Set device register to acknowledge completion</li>
</ol></li>
<li>Problem: Polling is slow</li>
<li>Solution: Use interrupts
<ul>
<li>Make device raise interrupt when it is complete</li>
<li>Have a separate interrupt handler to make device ready again</li>
</ul></li>
</ul>
<h2 id="access">Access</h2>
<p>A device driver accesses device registers through two options:</p>
<h3 id="special-io-instructions">Special I/O instructions</h3>
<ul>
<li>Device registers are assigned 'port' numbers</li>
<li>Instructions transfer data between a specified port and a CPU register</li>
</ul>
<h3 id="memory-mapped-io">Memory-mapped I/O</h3>
<ul>
<li>Each device register has a physical memory address</li>
<li>Device drivers can read/write to device registers using load and store instructions</li>
</ul>
<h4 id="os161-1">OS/161</h4>
<ul>
<li>32 x 64KB device slots</li>
<li>Each device is assigned to a device slot</li>
<li>Device register and data buffer are memory-mapped to slot</li>
<li>Use <code>kseg1</code> of kernel space (to avoid caching, since device will modify values)</li>
</ul>
<h2 id="data-transfer-tofrom-devices">Data Transfer To/From Devices</h2>
<h4 id="program-controlled-io">Program-controlled I/O</h4>
<ul>
<li>Device driver moves data between memory and a buffer on the device</li>
<li>Simple, but takes CPU time</li>
<li>os/161 does this</li>
</ul>
<h4 id="direct-memory-access-dma">Direct Memory Access (DMA)</h4>
<ul>
<li>Device moves data to/from memory</li>
<li>CPU is free</li>
<li>CPU initializes data transfer and is notified by device when transfer completes</li>
<li>CPU is the bus master of the disk device</li>
<li>Disk is bus master of memory</li>
</ul>
<h3 id="os161-2">os/161</h3>
<ul>
<li>Uses Program-controlled I/O</li>
<li>Device Driver Write Handler
<ol start="2" style="list-style-type: decimal">
<li>Copy data from memory to device transfer buffer</li>
<li>Write target sector number to register</li>
<li>Write 'write' command to register</li>
</ol></li>
<li>Interrupt Handler
<ol style="list-style-type: decimal">
<li>Write disk status register to acknowledge completion</li>
</ol></li>
</ul>
<h2 id="disk-drives">Disk Drives</h2>
<ul>
<li>Array of numbered blocks (sectors) of the same size</li>
<li>Blocks are the unit of transfer</li>
<li>Storage is non-volatile</li>
<li>Disk platter has a bunch of tracks</li>
<li>Arm needs to be on the right track for disk head read things</li>
<li>Sometimes double sided with two platters and arms</li>
<li>Performance:
<ul>
<li>Large files should be on outer track to be read quickly</li>
</ul></li>
</ul>
<h3 id="cost">Cost</h3>
<h4 id="moving-data-tofrom-a-disk">Moving data to/from a disk</h4>
<ul>
<li><strong>Seek time</strong>: moving disk head to appropriate track
<ul>
<li>Depends on distance between previous request and current request</li>
<li>Assume to be linear</li>
<li>~10ms</li>
</ul></li>
<li><strong>Rotational Latency</strong>: time for desired sectors to spin to disk head
<ul>
<li>Depends on rotational speed of disk</li>
<li>~8ms</li>
</ul></li>
<li><strong>Transfer time</strong>: time for desired sectors to spin past disk head
<ul>
<li>Depends on number of sectors needed and the rotational speed of disk</li>
<li>~8ms</li>
</ul></li>
<li><strong>Request Service Time</strong>: sum of seek time, rotational latency, transfer time</li>
</ul>
<h4 id="performance-implications">Performance Implications</h4>
<ul>
<li>Large transfers are more efficient than smaller ones</li>
<li>Sequential I/O is faster than non-sequential I/O</li>
</ul>
<h3 id="disk-head-scheduling">Disk Head Scheduling</h3>
<ul>
<li>Goal: reduce seek times by controlling request serving order</li>
</ul>
<h4 id="first-come-first-serve-fcfs">First Come First Serve (FCFS)</h4>
<ul>
<li>Handle requests in the order they arrive</li>
<li>Fair and simple, but no optimization</li>
</ul>
<h4 id="shortest-seek-time-first-sstf">Shortest Seek Time First (SSTF)</h4>
<ul>
<li>Choose closest request</li>
<li>Reduced seek times, but requests may starve</li>
</ul>
<h4 id="elevator-algorithm-scan">Elevator Algorithm (SCAN)</h4>
<ul>
<li>Move in one direction until there are no requests in front, then reverse</li>
<li>Reduces seek times and avoids starvation</li>
</ul>
<h2 id="solid-state-drives">Solid State Drives</h2>
<h3 id="dram">DRAM</h3>
<ul>
<li>Made of transistors with capacitors</li>
<li>Problem: leaks charge, needs to be periodically refreshed by power</li>
</ul>
<h3 id="flash-memory">Flash Memory</h3>
<ul>
<li>Floating gate transistors</li>
<li>Traps electrons in a quantum cage (physics magic)</li>
<li>Holding electrons = 0</li>
<li>Data is arranged into blocks and pages</li>
<li>Advantages: Faster access, no mechanical parts, larger operational temperature ranges</li>
<li>Disadvantages: Limited lifespan, data unrecoverable from dead drives, poor performance in full drives</li>
</ul>
<h4 id="writing">Writing</h4>
<ul>
<li>Pages initialized to 1, and can transition 1 -&gt; 0 at page level</li>
<li>Switching 0 -&gt; 1 requires high voltage, can only be applied to blocks</li>
<li>Solution: Read block to memory, re-initialize block, update and re-write
<ul>
<li>Problem: Slow, lots of re-initializing and copying</li>
</ul></li>
<li>Solution: Write to an unused page and update translation table
<ul>
<li>Mark original page as invalid, to be garbage collected</li>
<li>Problem: Requires garbage collector</li>
<li>Problem: Updates are slow if drive is near full</li>
</ul></li>
</ul>
<h4 id="wear">Wear</h4>
<ul>
<li>SSD's have limited number of write cycles</li>
<li>If a block is not writeable, it becomes read-only</li>
<li>If a lot of blocks are read-only, the disk is read-only</li>
<li><strong>Wear-levels</strong> ensure that write cycles are spread across all blocks</li>
<li><em>Defragmentation</em> is bad for SSD's as it increases write cycles without any benefits
<ul>
<li>Random and sequential access have about the same cost</li>
</ul></li>
</ul>
<h1 id="file-systems">File Systems</h1>
<h2 id="files">Files</h2>
<ul>
<li>Persistent, named data objects</li>
<li>File size may change over time</li>
<li>File has meta-data: owner, permissions, file type, timestamps</li>
</ul>
<h3 id="file-interface">File Interface</h3>
<ul>
<li>Open
<ul>
<li>Returns a file identifier (descriptor)</li>
<li>Adds entry to descriptor table that has more information on file</li>
</ul></li>
<li>Close
<ul>
<li>Removes entry from descriptor table</li>
</ul></li>
<li>Read, Write, Seek
<ul>
<li>Read: Copies data from file to virtual address space</li>
<li>Write: Copies data from virtual address space into file</li>
<li>Seek: Enables non-sequential reading/writing</li>
</ul></li>
<li>Get/Set File Meta-Data
<ul>
<li>e.g <code>fstat</code>, <code>chmod</code></li>
</ul></li>
</ul>
<h3 id="file-position">File Position</h3>
<ul>
<li>Every file descriptor has an associated file position</li>
<li>Read and write operations start from the current file position and update the current file position</li>
<li>Sequential file I/O is easy</li>
<li><code>lseek</code> is used for non-sequential file I/O to change the file position</li>
</ul>
<h2 id="directories">Directories</h2>
<ul>
<li>A directory maps <em>file names</em> to <em>i-numbers</em>
<ul>
<li>i-number = unique identifier for a file or directory</li>
<li>i-number is used to find data and meta-data of a file</li>
</ul></li>
<li>Directories can be viewed as a tree</li>
<li>Files and Directories can be identified by <em>pathnames</em></li>
<li>Applications refer to files using pathnames</li>
<li>Special type of directory file that contains directory entries</li>
<li>Each directory entry consists of a file name and i-number</li>
</ul>
<h3 id="links">Links</h3>
<ul>
<li>A <em>hard link</em> is an association between a name and an i-number
<ul>
<li>Hard links are created with the file</li>
<li>A file can have multiple hard links</li>
</ul></li>
</ul>
<h4 id="unlinking">Unlinking</h4>
<ul>
<li>Unlinking removes a hard link</li>
<li>The file is removed when the last hard link is removed</li>
</ul>
<h2 id="multiple-file-systems">Multiple File Systems</h2>
<ul>
<li>A global file namespace is needed</li>
<li>e.g Windows mounts it on C:, D:,...</li>
<li>e.g Unix mounts it in the existing namespace</li>
<li>New namespace is temporary</li>
</ul>
<h2 id="file-system-implementation">File System Implementation</h2>
<ul>
<li>Persistent data:
<ul>
<li>File data</li>
<li>File meta-data</li>
<li>Directories and links</li>
<li>File system meta-data</li>
</ul></li>
<li>Non-persistent information:
<ul>
<li>Open files per process</li>
<li>File position for each open file</li>
<li>Cached copies of persistent data</li>
</ul></li>
<li>Hardware
<ul>
<li>Memory is byte addressable</li>
<li>Disk is sector addressable</li>
<li>Problem: Need multiple sectors to store file system</li>
<li>Solution: 8 consecutive sectors are grouped into a block
<ul>
<li>Better spatial locality</li>
<li>Less block pointers</li>
<li>Convenient size for on-demand paging</li>
</ul></li>
</ul></li>
</ul>
<h3 id="vsfs-very-simple-file-system">VSFS (Very Simple File System)</h3>
<ul>
<li>e.g 256KB disk, 512B sector, 512 sectors, 64 block</li>
<li>Most blocks should be for storing user data (56 blocks)</li>
<li>Array of i-nodes (5 blocks)
<ul>
<li>i-nodes limit the number of files there can be (80 i-nodes = 80 files max)</li>
</ul></li>
<li>Bitmap / Free list for data-blocks and i-nodes (2 blocks)
<ul>
<li>Tracks available and used i-nodes / data-blocks</li>
</ul></li>
<li>Superblock (1st block)
<ul>
<li>Contains meta-information about the file system</li>
<li>e.g How many nodes / blocks, location of bitmap</li>
</ul></li>
</ul>
<h3 id="i-nodes">i-nodes</h3>
<ul>
<li>Fixed size index structure holding both file meta-data and pointers to data blocks</li>
<li>Stores:
<ul>
<li>file type, file permissions, file length, number of file blocks,</li>
<li>timestamps,</li>
<li>number of hard-links,</li>
<li>direct data block pointers,</li>
<li>indirect data block pointers (single, double, triple)</li>
<li>DOES NOT STORE the name</li>
</ul></li>
</ul>
<h3 id="bitmap">Bitmap</h3>
<ul>
<li>Stores availability of i-nodes and data blocks</li>
</ul>
<h4 id="vsfs">VSFS</h4>
<ul>
<li>Assuming enough room for 12 direct pointers</li>
<li>Maximum file size will be limited (12 * 4KB = 48KB)</li>
<li>Problem: Can't store big files</li>
<li>Solution: Indirect blocks
<ul>
<li>Point to a block of direct pointers</li>
<li>Double indirect pointer can also point to block of indirect pointers</li>
<li>Triple indirect pointers point to block to double indirect pointers</li>
<li>Increases possible file size exponentially</li>
<li>Direct pointers still have fastest data access</li>
</ul></li>
</ul>
<h2 id="file-system-design">File System Design</h2>
<ul>
<li>How many i-nodes (Number of files)</li>
<li>How many direct vs indirect blocks (Size of files)</li>
<li>Block size</li>
<li>General File System
<ul>
<li>Most files are small</li>
<li>Average file size is growing
<ul>
<li>Plan for larger file sizes than used today</li>
</ul></li>
<li>Most bytes are stored in large files
<ul>
<li>Need indirect data block pointers<br />
</li>
</ul></li>
<li>File systems contain lots of files
<ul>
<li>Lots of i-nodes</li>
</ul></li>
<li>File systems are roughly half full
<ul>
<li>Use faster parts of drive first</li>
</ul></li>
<li>Directories are typically small
<ul>
<li>Directory list can be simple</li>
</ul></li>
</ul></li>
</ul>
<h2 id="reading-from-a-file-subfoldersubfile">Reading From A File (/subfolder/subfile)</h2>
<ol style="list-style-type: decimal">
<li>Read the root i-node</li>
<li>Read the directory information
<ul>
<li>Find the subfolder (error if it doesn't exist)</li>
</ul></li>
<li>Read the subfolder i-node</li>
<li>Read the subfolder information
<ul>
<li>Find the subfile</li>
</ul></li>
<li>Read the subfile i-node (update cache data, disk update later)
<ul>
<li>Check permissions</li>
<li>Add entry to per-process descriptor table</li>
<li>Increment counter in global open file table</li>
</ul></li>
<li>Open the file
<ul>
<li>Find data blocks and read it</li>
<li>Update file access time</li>
<li>Update file position in descriptor table</li>
</ul></li>
</ol>
<h2 id="creating-a-file-subfoldersubfile">Creating a File (/subfolder/subfile)</h2>
<ol style="list-style-type: decimal">
<li>Read root i-node</li>
<li>Read subfolder
<ul>
<li>Subfile does not exist in subfolder</li>
</ul></li>
<li>Read i-node bitmap
<ul>
<li>Find and allocate unused i-node in i-node bitmap</li>
<li>Read block of i-nodes (so we can write them back later)</li>
</ul></li>
<li>Update subfolder i-node to include new i-node entry
<ul>
<li>Increase directory size</li>
<li>Update last accessed / modified timestamp</li>
</ul></li>
<li>Modify i-node to contain new file information
<ul>
<li>Write data block pointers</li>
</ul></li>
</ol>
<h2 id="in-memory-non-persistent-structures">In-Memory (Non-Persistent) Structures</h2>
<ul>
<li>Descriptor table for each process
<ul>
<li>First 3 entries: stdin, stdout, stderr</li>
<li>Tracks open file descriptors</li>
</ul></li>
<li>Open file table
<ul>
<li>Makes sure that file can be written to and read from after it's been deleted, but still open</li>
</ul></li>
<li>i-node cache</li>
<li><p>block cache</p></li>
<li><p>These can be safely lost when power goes out</p></li>
</ul>
<h2 id="failures">Failures</h2>
<ul>
<li>e.g. Deleting a file
<ol style="list-style-type: decimal">
<li>Remove entry from directory</li>
<li>Remove file index (i-node) from i-node bitmap</li>
<li>Mark file's data blocks as free</li>
</ol></li>
<li>What if power loss occurs after (1) ?
<ul>
<li>Unreachable files are taking up space</li>
</ul></li>
<li>e.g. Moving file from dir A to dir B
<ol style="list-style-type: decimal">
<li>Update directory A to remove first link</li>
<li>Update directory B to add link</li>
</ol></li>
<li>What if power loss occurs after (1) ?
<ul>
<li>Lost, unreachable file</li>
</ul></li>
<li>What if the steps are switched?
<ul>
<li>Corrupted file structure: Two hard links to a dir</li>
<li>Could result in a recursive file structure</li>
</ul></li>
<li>File structure should be <em>crash consistent</em> (consistent whenever restarting from a failure)
<ul>
<li>Solution: Run a consistency check on bootup
<ul>
<li>e.g Linux <code>fsck</code></li>
<li>Finds and attempts to repair inconsistent file system data structures</li>
<li>Problem: May take a long time</li>
</ul></li>
<li>Solution: Journaling
<ul>
<li>Log meta-data changes so that sequences of changes can be written to disk in a single operation</li>
<li><em>Write-ahead logging</em>: Update disk data structures after changes are journaled</li>
<li>After a failure, redo journaled updates that were not completed</li>
<li>Only redo full log entries (begin - ... - commit)</li>
</ul></li>
</ul></li>
</ul>
<h2 id="chaining">Chaining</h2>
<ul>
<li>Alternative to per-file index of direct and indirect pointers to access blocks</li>
<li>Chaining
<ul>
<li>Each block includes a pointer to the next block</li>
</ul></li>
<li>External chaining
<ul>
<li>Chain is in an external data structure</li>
<li>e.g Microsoft's FAT (File Allocation Table)</li>
</ul></li>
<li>Saves space (no direct / indirect pointers to unused data blocks)</li>
<li>Good for sequential access</li>
<li>Problem: Slow for random access</li>
<li>Solution: Eternal chaining with a special file access table that specifies all the file chains</li>
</ul>
<h2 id="review-questions">Review Questions</h2>
<ul>
<li>Given a file offset, how do you determine which block pointers must be accessed to determine the block location?</li>
<li>Understand design decisions for a file system
<ul>
<li>Why use indirect pointers?</li>
<li>When to use an indexed file system vs chaining?</li>
</ul></li>
<li>How are directories implemented?</li>
<li>What is a hard link?</li>
<li>Given a file, which i-nodes / data blocks / bitmap nodes need to be accessed?</li>
</ul>
</body>
</html>
